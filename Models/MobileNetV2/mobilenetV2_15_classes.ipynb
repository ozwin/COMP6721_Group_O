{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "from torchsummary import summary\n",
    "import torchvision\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torchvision.models as models\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import os\n",
    "from google.colab import files\n",
    "from google.colab import drive\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drive.mount('/content/drive')\n",
    "from zipfile import ZipFile\n",
    "file_name = \"/content/drive/MyDrive/15-classes.zip\"\n",
    "with ZipFile(file_name, 'r') as zip:\n",
    "  zip.extractall()\n",
    "  print('Done')\n",
    "\n",
    "picture = plt.imread('/content/15-classes/train/20/0b103c4331bb47f4890d6e0ec96bf9bf.jpg')\n",
    "imageShow = plt.imshow(picture)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mobilenetV2=models.mobilenet_v2(pretrained=False,num_classes=15)\n",
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "count_parameters(mobilenetV2)\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "mobilenetV2.to(device)\n",
    "print(\"Device: {}\".format(device))\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(mobilenetV2.parameters(), lr=0.0002,momentum=0.9)\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=20, eta_min=0.0001)\n",
    "n_epochs = 100\n",
    "epoch_count = 0\n",
    "# resnet18Model.load_state_dict(torch.load('/content/82-epoch-output.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#import this file to train models and pass the  name of the datset\n",
    "# extract zip files\n",
    "# load the images and labels based on the dataset requested\n",
    "# do the pre-processing , batch normalization , flip etc\n",
    "\n",
    "# Transofrmations for preprocessedSnakeImages dataset\n",
    "# Reference from https://www.youtube.com/watch?v=z3kB3ISIPAg&list=PL3Dh_99BJkCEhE7Ri8W6aijiEqm3ZoGRq&index=4\n",
    "training_path = '/content/15-classes/train/'\n",
    "test_path = '/content/15-classes/test'\n",
    "val_path = '/content/15-classes/val'\n",
    "def transformDS1( batchSize, inputSize):\n",
    "\n",
    "    training_transforms = transforms.Compose([transforms.Resize((inputSize,inputSize)),transforms.ToTensor()])\n",
    "    train_dataset = torchvision.datasets.ImageFolder(root=training_path,transform = training_transforms)\n",
    "    train_Loader = torch.utils.data.DataLoader(dataset = train_dataset,batch_size=batchSize,shuffle=False)\n",
    "    mean, std = get_mean_std(train_Loader)\n",
    "    train_transforms = transforms.Compose([\n",
    "        transforms.Resize((inputSize,inputSize)),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.RandomRotation(10),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(torch.Tensor(mean),torch.Tensor(std))\n",
    "    ])\n",
    "\n",
    "    test_transforms = transforms.Compose([\n",
    "        transforms.Resize((inputSize,inputSize)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(torch.Tensor(mean),torch.Tensor(std))\n",
    "    ])\n",
    "\n",
    "    val_transforms = transforms.Compose([\n",
    "        transforms.Resize((inputSize,inputSize)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(torch.Tensor(mean),torch.Tensor(std))\n",
    "    ])\n",
    "    \n",
    "    train_dataset = torchvision.datasets.ImageFolder(root=training_path,transform=train_transforms)\n",
    "    test_dataset = torchvision.datasets.ImageFolder(root=test_path,transform=test_transforms)\n",
    "    val_dataset = torchvision.datasets.ImageFolder(root=val_path,transform=val_transforms)\n",
    "\n",
    "    train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batchSize,\n",
    "    shuffle=True,drop_last=False,num_workers=0)\n",
    "    data_loader_test = torch.utils.data.DataLoader(test_dataset, batch_size=batchSize,\n",
    "    shuffle=True,drop_last=False,num_workers=0)\n",
    "    val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=batchSize,\n",
    "    shuffle=True,drop_last=False,num_workers=0)\n",
    "\n",
    "    return train_loader,data_loader_test,val_loader\n",
    "\n",
    "def get_mean_std(loader):\n",
    "    mean = 0.\n",
    "    std = 0.\n",
    "    total_images_count = 0\n",
    "    for images,_ in loader:\n",
    "        images_count_in_batch = images.size(0)\n",
    "        images =images.view(images_count_in_batch,images.size(1),-1)\n",
    "        mean+=images.mean(2).sum(0)\n",
    "        std+=images.std(2).sum(0)\n",
    "        total_images_count+=images_count_in_batch\n",
    "    mean /= total_images_count\n",
    "    std /= total_images_count\n",
    "    return mean,std\n",
    "\n",
    "def show_transformed_images(train_loader):\n",
    "    batch=next(iter(train_loader))\n",
    "    images,labels = batch\n",
    "    grid = torchvision.utils.make_grid(images,nrow=3)\n",
    "    plt.figure(figsize=(11,11))\n",
    "    plt.imshow(np.transpose(grid,(1,2,0)))\n",
    "    plt.show()\n",
    "    print(\"labels:\",labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model,test_loader):\n",
    "    model.eval()\n",
    "    predicted_correct =0\n",
    "    total = 0\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    with torch.no_grad():\n",
    "        for data in test_loader:\n",
    "            images,labels = data\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            total+=labels.size(0)\n",
    "            outputs = model(images)\n",
    "            _,predicted = torch.max(outputs,1)\n",
    "            predicted_correct += (predicted == labels).sum().item()\n",
    "    epoch_accuracy = 100.0* predicted_correct/total\n",
    "    print(\"Testing Data: Epoch Accuracy: %.3f\"%(epoch_accuracy))\n",
    "    return epoch_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader,test_loader,val_loader = transformDS1(32,224)\n",
    "show_transformed_images(val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "Accuracies = [] \n",
    "valAccuracies = []\n",
    "valLoss = []\n",
    "trainLoss = []\n",
    "total_steps = len(train_loader)\n",
    "t1 = time.time()\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "validation_accuracy = 0\n",
    "for epoch in range(n_epochs):\n",
    "    print(\"Epoch number %d\" %(epoch+1))\n",
    "    mobilenetV2.train()\n",
    "    running_loss = 0.0\n",
    "    running_correct = 0.0\n",
    "    val_loss = 0.0\n",
    "    total = 0\n",
    "    for i, data in enumerate(train_loader):\n",
    "      images,labels = data\n",
    "      device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "      images = images.to(device)\n",
    "      labels = labels.to(device)\n",
    "      total+=labels.size(0)\n",
    "\n",
    "      optimizer.zero_grad()\n",
    "      outputs = mobilenetV2(images)\n",
    "      _,predicted = torch.max(outputs.data,1)\n",
    "      loss = criterion(outputs,labels)\n",
    "      loss.backward()\n",
    "      optimizer.step()\n",
    "      \n",
    "      running_loss+=loss.item()\n",
    "      running_correct += (labels==predicted).sum().item()\n",
    "     \n",
    "      \n",
    "      training_accuracy = (running_correct / total) * 100\n",
    "    validation_accuracy = 0\n",
    "    mobilenetV2.eval()\n",
    "    with torch.no_grad(): \n",
    "        val_correct = 0\n",
    "        val_total = 0\n",
    "        val_loss = 0\n",
    "        for data in val_loader:\n",
    "            images, val_labels = data[0].to(device), data[1].to(device)\n",
    "            images = images.to(device)\n",
    "            val_labels = val_labels.to(device)\n",
    "            outputs = mobilenetV2(images)\n",
    "            lossVal = criterion(outputs,val_labels)\n",
    "            val_loss += lossVal.item()\n",
    "            # Validation set accuracy\n",
    "            \n",
    "            _,predicted = torch.max(outputs.data, 1)\n",
    "            val_correct += (predicted == val_labels).sum().item()\n",
    "            val_total  += val_labels.size(0)\n",
    "          \n",
    "        validation_accuracy = (val_correct / val_total) *100\n",
    "\n",
    "    scheduler.step()  \n",
    "    epoch_loss = running_loss/len(train_loader)\n",
    "    val_loss = val_loss/len(val_loader)\n",
    "    epoch_accuracy = 100.00 * running_correct/total\n",
    "    Accuracies.append(epoch_accuracy)\n",
    "    valAccuracies.append(validation_accuracy)\n",
    "    trainLoss.append(epoch_loss)\n",
    "    valLoss.append(val_loss)\n",
    "    \n",
    "    print(\"Training Data: Epoch Loss: %.3f, Epoch Accuracy: %.3f, Validation Loss: %.3f\"%(epoch_loss,epoch_accuracy,val_loss))\n",
    "\n",
    "print(\"---Training finished in {} seconds---\".format(time.time()-t1))\n",
    "epoch_count+=n_epochs\n",
    "torch.save(mobilenetV2.state_dict(), \"/content/15-Class-\"+str(epoch_count)+\"-epoch.pt\")\n",
    "\n",
    "test_acc = evaluate_model(mobilenetV2,test_loader)\n",
    "dict = {'Training': Accuracies, 'Validation': valAccuracies} \n",
    "dictLoss = {'Training': trainLoss,'Validation': valLoss}\n",
    "df = pd.DataFrame(dict)\n",
    "df2 = pd.DataFrame(dictLoss)\n",
    "df.to_csv(\"/content/Accuracies\"+str(epoch_count)+\".csv\")\n",
    "df2.to_csv(\"/content/Loss\"+str(epoch_count)+\".csv\")\n",
    "files.download(\"/content/15-Class-\"+str(epoch_count)+\"-epoch.pt\")\n",
    "files.download(\"/content/Accuracies\"+str(epoch_count)+\".csv\")\n",
    "files.download(\"/content/Loss\"+str(epoch_count)+\".csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(val_loss/len(val_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting Accuracies Vs Epochs\n",
    "plt.plot(range(n_epochs),Accuracies)\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Training Accuracies\")\n",
    "plt.title(\"Training Accuracy Vs Epochs\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting Validation Accuracies Vs Train Accuracies on Epochs\n",
    "plt.plot(range(n_epochs),Accuracies, label=\"Training\")\n",
    "plt.plot(range(n_epochs),valAccuracies, label=\"Validation\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Accuracies\")\n",
    "plt.title(\"Training vs Validation Accuracies\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting Validation Accuracies Vs Train Accuracies on Epochs\n",
    "plt.plot(range(n_epochs),trainLoss, label=\"Training\")\n",
    "plt.plot(range(n_epochs),valLoss, label=\"Validation\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"Training vs Validation Loss\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculate Confusion Matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sn\n",
    "import pandas as pd\n",
    "from sklearn.metrics import confusion_matrix,accuracy_score,precision_score,recall_score,ConfusionMatrixDisplay\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sn\n",
    "import pandas as pd\n",
    "\n",
    "y_pred = []\n",
    "y_true = []\n",
    "\n",
    "# iterate over test data\n",
    "for data in test_loader:\n",
    "        inputs, labels = data[0].to(device), data[1].to(device)\n",
    "        output = mobilenetV2(inputs) # Feed Network\n",
    "\n",
    "        output = (torch.max(torch.exp(output), 1)[1]).data.cpu().numpy()\n",
    "        y_pred.extend(output) # Save Prediction\n",
    "        \n",
    "        labels = labels.data.cpu().numpy()\n",
    "        y_true.extend(labels) # Save Truth\n",
    "\n",
    "# constant for classes\n",
    "classes = (0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,14)\n",
    "\n",
    "# Build confusion matrix\n",
    "confusion_matrix(y_true, y_pred)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix(y_true, y_pred),display_labels=classes)\n",
    "fig,ax = plt.subplots()\n",
    "fig.set_size_inches(13,13)\n",
    "plt.title(\"Confusion Matrix ResNet 18 (15-Classes)\")\n",
    "disp.plot(ax=ax)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculate Confusion Matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sn\n",
    "import pandas as pd\n",
    "from sklearn.metrics import confusion_matrix,accuracy_score,precision_score,recall_score,ConfusionMatrixDisplay\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sn\n",
    "import pandas as pd\n",
    "\n",
    "y_pred = []\n",
    "y_true = []\n",
    "\n",
    "# iterate over test data\n",
    "for data in test_loader:\n",
    "        inputs, labels = data[0].to(device), data[1].to(device)\n",
    "        output = mobilenetV2(inputs) # Feed Network\n",
    "\n",
    "        output = (torch.max(torch.exp(output), 1)[1]).data.cpu().numpy()\n",
    "        y_pred.extend(output) # Save Prediction\n",
    "        \n",
    "        labels = labels.data.cpu().numpy()\n",
    "        y_true.extend(labels) # Save Truth\n",
    "\n",
    "# constant for classes\n",
    "classes = (0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,14)\n",
    "\n",
    "# Build confusion matrix\n",
    "confusion_matrix(y_true, y_pred)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix(y_true, y_pred),display_labels=classes)\n",
    "fig,ax = plt.subplots()\n",
    "fig.set_size_inches(13,13)\n",
    "plt.title(\"Confusion Matrix Mobilenet V2 (15-Classes)\")\n",
    "disp.plot(ax=ax)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit (microsoft store)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "546a118fabd46aa61850e1abbed3a791a1556d66942a03e04096875cc83195b3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
