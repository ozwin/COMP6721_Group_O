{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1f5d6e24",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ozwin\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "from torchsummary import summary\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e32995de",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "from zipfile import ZipFile\n",
    "file_name = \"/content/drive/MyDrive/5-class.zip\"\n",
    "with ZipFile(file_name, 'r') as zip:\n",
    "  zip.extractall()\n",
    "  print('Done')\n",
    "\n",
    "picture = plt.imread('/content/5-class/preprocessed-cleaned-set/train/class-1/00056e9548477cda7a885bb423cb668c.jpg')\n",
    "imageShow = plt.imshow(picture)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "488abace",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNetBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, identity_downsample=None, stride=1):\n",
    "        super(ResNetBlock, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=stride, padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
    "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.identity_downsample = identity_downsample\n",
    "        \n",
    "    def forward(self, x):\n",
    "        identity = x\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.bn2(x)\n",
    "        if self.identity_downsample is not None:\n",
    "            identity = self.identity_downsample(identity)\n",
    "        x += identity\n",
    "        x = self.relu(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dfb015e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNet_18(nn.Module):\n",
    "    \n",
    "    def __init__(self, image_channels, num_classes):\n",
    "        \n",
    "        super(ResNet_18, self).__init__()\n",
    "        self.in_channels = 64\n",
    "        self.conv1 = nn.Conv2d(image_channels, 64, kernel_size=7, stride=2, padding=3)\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "        \n",
    "        #resnet layers\n",
    "        self.layer1 = self.__make_layer(64, 64, stride=1)\n",
    "        self.layer2 = self.__make_layer(64, 128, stride=2)\n",
    "        self.layer3 = self.__make_layer(128, 256, stride=2)\n",
    "        self.layer4 = self.__make_layer(256, 512, stride=2)\n",
    "        \n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.fc = nn.Linear(512, num_classes)\n",
    "        \n",
    "    def __make_layer(self, in_channels, out_channels, stride):\n",
    "        \n",
    "        identity_downsample = None\n",
    "        if stride != 1:\n",
    "            identity_downsample = self.identity_downsample(in_channels, out_channels)\n",
    "            \n",
    "        return nn.Sequential(\n",
    "            ResNetBlock(in_channels, out_channels, identity_downsample=identity_downsample, stride=stride), \n",
    "            ResNetBlock(out_channels, out_channels)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool(x)\n",
    "        \n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "        \n",
    "        x = self.avgpool(x)\n",
    "        x = x.view(x.shape[0], -1)\n",
    "        x = self.fc(x)\n",
    "        return x \n",
    "    \n",
    "    def identity_downsample(self, in_channels, out_channels):\n",
    "        \n",
    "        return nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=2, padding=1), \n",
    "            nn.BatchNorm2d(out_channels)\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db5b52da",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ResNet_18(3, 5) \n",
    "# change classes based on data set used\n",
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "count_parameters(model)\n",
    "# summary(model,input_size=(3,32,32))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b94c59b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b775d6c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 5\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)\n",
    "# weight_decay=1e-4\n",
    "# lr_scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, patience=5, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "744a7e8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "#import this file to train models and pass the  name of the datset\n",
    "# extract zip files\n",
    "# load the images and labels based on the dataset requested\n",
    "# do the pre-processing , batch normalization , flip etc\n",
    "\n",
    "# Transofrmations for preprocessedSnakeImages dataset\n",
    "# Reference from https://www.youtube.com/watch?v=z3kB3ISIPAg&list=PL3Dh_99BJkCEhE7Ri8W6aijiEqm3ZoGRq&index=4\n",
    "training_path = '/content/5-class/preprocessed-cleaned-set/train/'\n",
    "test_path = '/content/5-class/preprocessed-cleaned-set/test'\n",
    "val_path = '/content/5-class/preprocessed-cleaned-set/val'\n",
    "def transformDS1( batchSize, inputSize):\n",
    "\n",
    "    training_transforms = transforms.Compose([transforms.Resize((inputSize,inputSize)),transforms.ToTensor()])\n",
    "    train_dataset = torchvision.datasets.ImageFolder(root=training_path,transform = training_transforms)\n",
    "    train_Loader = torch.utils.data.DataLoader(dataset = train_dataset,batch_size=batchSize,shuffle=False)\n",
    "\n",
    "    mean, std = get_mean_std(train_Loader)\n",
    "\n",
    "    train_transforms = transforms.Compose([\n",
    "        transforms.Resize((inputSize,inputSize)),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.RandomRotation(10),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(torch.Tensor(mean),torch.Tensor(std))\n",
    "    ])\n",
    "\n",
    "    test_transforms = transforms.Compose([\n",
    "        transforms.Resize((inputSize,inputSize)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(torch.Tensor(mean),torch.Tensor(std))\n",
    "    ])\n",
    "\n",
    "    val_transforms = transforms.Compose([\n",
    "        transforms.Resize((inputSize,inputSize)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(torch.Tensor(mean),torch.Tensor(std))\n",
    "    ])\n",
    "    train_dataset = torchvision.datasets.ImageFolder(root=training_path,transform=train_transforms)\n",
    "    test_dataset = torchvision.datasets.ImageFolder(root=test_path,transform=test_transforms)\n",
    "    val_dataset = torchvision.datasets.ImageFolder(root=val_path,transform=val_transforms)\n",
    "\n",
    "\n",
    "    data_loader_train = torch.utils.data.DataLoader(train_dataset, batch_size=batchSize,\n",
    "    shuffle=True,drop_last=False,num_workers=0)\n",
    "    data_loader_test = torch.utils.data.DataLoader(test_dataset, batch_size=batchSize,\n",
    "    shuffle=True,drop_last=False,num_workers=0)\n",
    "    data_loader_val = torch.utils.data.DataLoader(val_dataset, batch_size=batchSize,\n",
    "    shuffle=True,drop_last=False,num_workers=0)\n",
    "\n",
    "    return data_loader_train,data_loader_test,data_loader_val\n",
    "\n",
    "def get_mean_std(loader):\n",
    "    mean = 0.\n",
    "    std = 0.\n",
    "    total_images_count = 0\n",
    "    for images,_ in loader:\n",
    "        images_count_in_batch = images.size(0)\n",
    "        images =images.view(images_count_in_batch,images.size(1),-1)\n",
    "        mean+=images.mean(2).sum(0)\n",
    "        std+=images.std(2).sum(0)\n",
    "        total_images_count+=images_count_in_batch\n",
    "    mean /= total_images_count\n",
    "    std /= total_images_count\n",
    "    return mean,std\n",
    "\n",
    "def show_transformed_images(data_loader_train):\n",
    "    batch=next(iter(data_loader_train))\n",
    "    images,labels = batch\n",
    "    grid = torchvision.utils.make_grid(images,nrow=3)\n",
    "    plt.figure(figsize=(11,11))\n",
    "    plt.imshow(np.transpose(grid,(1,2,0)))\n",
    "    plt.show()\n",
    "    print(\"labels:\",labels)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0618cdbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_loader_train,data_loader_test,data_loader_val = transformDS1(32,224)\n",
    "show_transformed_images(data_loader_val)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10e3e6f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "############ Define the training loop here ###########\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Device: {}\".format(device))\n",
    "model.to(device)\n",
    "num_epochs = 10\n",
    "Accuracy=[]\n",
    "total_steps = len(data_loader_train)\n",
    "t1 = time.time()\n",
    "for epoch in range(num_epochs):\n",
    "    for i, data in enumerate(data_loader_train):\n",
    "        images, labels = data[0].to(device), data[1].to(device)\n",
    "        # Forward pass\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        # Backprop and optimisation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        # Training accuracy\n",
    "        total = labels.size(0)\n",
    "        _,predicted = torch.max(outputs.data, 1)\n",
    "        correct = (predicted == labels).sum().item()\n",
    "        if (i + 1) % 100 == 0:\n",
    "            validation_accuracy = 0\n",
    "            model.eval()\n",
    "            with torch.no_grad(): \n",
    "                val_correct = 0\n",
    "                val_total = 0\n",
    "                for data in data_loader_val:\n",
    "                    images, val_labels = data[0].to(device), data[1].to(device)\n",
    "                    outputs = model(images)\n",
    "                    # Validation set accuracy\n",
    "                    val_total = val_labels.size(0)\n",
    "                    _,predicted = torch.max(outputs.data, 1)\n",
    "                    val_correct += (predicted == val_labels).sum().item()\n",
    "                    val_total  += val_labels.size(0)\n",
    "\n",
    "            validation_accuracy = 100 * (val_correct / val_total)\n",
    "            training_accuracy = (correct / total) * 100\n",
    "            print('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}, Training Accuracy: {:.2f}%, Validation Accuracy: {:.2f}%'\n",
    "                .format(epoch + 1, num_epochs, i + 1, total_steps, loss.item(), training_accuracy , validation_accuracy))\n",
    "            Accuracy.append(training_accuracy)\n",
    "                            \n",
    "print(\"######## Training Finished in {} seconds ###########\".format(time.time()-t1))\n",
    "torch.save(model.state_dict(), \"/content/150-epoch-output.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01dafe2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.save(model.state_dict(), \"./content/drive/MyDrive\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c562765b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval() \n",
    "\n",
    "with torch.no_grad(): \n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for data in data_loader_test:\n",
    "        images, labels = data[0].to(device), data[1].to(device)\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "    print('Test Accuracy of the model on the {} test images: {} %'\n",
    "        .format(total, (correct / total) * 100))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "27c12e6cacbf7604865d82dba11605bee4bbecd8b82f9ede11b3d85a68a54965"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
