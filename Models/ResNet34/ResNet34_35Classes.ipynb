{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R7Ct63Ht7PEE"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "from zipfile import ZipFile\n",
        "file_name = \"/content/drive/MyDrive/35-classes.zip\"\n",
        "with ZipFile(file_name, 'r') as zip:\n",
        "  zip.extractall()\n",
        "  print('Done')\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torchvision.models as models\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch\n",
        "import numpy as np\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "c421p3lYBwI_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "training_path = '/content/35-classes/train/'\n",
        "test_path = '/content/35-classes/test'\n",
        "val_path = '/content/35-classes/val'\n",
        "def transformDS1( batchSize, inputSize):\n",
        "\n",
        "    training_transforms = transforms.Compose([transforms.Resize((inputSize,inputSize)),transforms.ToTensor()])\n",
        "    train_dataset = torchvision.datasets.ImageFolder(root=training_path,transform = training_transforms)\n",
        "    train_Loader = torch.utils.data.DataLoader(dataset = train_dataset,batch_size=batchSize,shuffle=False)\n",
        "\n",
        "    mean, std = get_mean_std(train_Loader)\n",
        "\n",
        "    train_transforms = transforms.Compose([\n",
        "        transforms.Resize((inputSize,inputSize)),\n",
        "        transforms.RandomHorizontalFlip(),\n",
        "        transforms.RandomRotation(10),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(torch.Tensor(mean),torch.Tensor(std))\n",
        "    ])\n",
        "\n",
        "    test_transforms = transforms.Compose([\n",
        "        transforms.Resize((inputSize,inputSize)),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(torch.Tensor(mean),torch.Tensor(std))\n",
        "    ])\n",
        "\n",
        "    val_transforms = transforms.Compose([\n",
        "        transforms.Resize((inputSize,inputSize)),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(torch.Tensor(mean),torch.Tensor(std))\n",
        "    ])\n",
        "    train_dataset = torchvision.datasets.ImageFolder(root=training_path,transform=train_transforms)\n",
        "    test_dataset = torchvision.datasets.ImageFolder(root=test_path,transform=test_transforms)\n",
        "    val_dataset = torchvision.datasets.ImageFolder(root=val_path,transform=val_transforms)\n",
        "\n",
        "\n",
        "    data_loader_train = torch.utils.data.DataLoader(train_dataset, batch_size=batchSize,\n",
        "    shuffle=True,drop_last=False,num_workers=0)\n",
        "    data_loader_test = torch.utils.data.DataLoader(test_dataset, batch_size=batchSize,\n",
        "    shuffle=True,drop_last=False,num_workers=0)\n",
        "    data_loader_val = torch.utils.data.DataLoader(val_dataset, batch_size=batchSize,\n",
        "    shuffle=True,drop_last=False,num_workers=0)\n",
        "\n",
        "    return data_loader_train,data_loader_test,data_loader_val\n",
        "\n",
        "def get_mean_std(loader):\n",
        "    mean = 0.\n",
        "    std = 0.\n",
        "    total_images_count = 0\n",
        "    for images,_ in loader:\n",
        "        images_count_in_batch = images.size(0)\n",
        "        images =images.view(images_count_in_batch,images.size(1),-1)\n",
        "        mean+=images.mean(2).sum(0)\n",
        "        std+=images.std(2).sum(0)\n",
        "        total_images_count+=images_count_in_batch\n",
        "    mean /= total_images_count\n",
        "    std /= total_images_count\n",
        "    return mean,std\n",
        "\n",
        "def show_transformed_images(data_loader_train):\n",
        "    batch=next(iter(data_loader_train))\n",
        "    images,labels = batch\n",
        "    grid = torchvision.utils.make_grid(images,nrow=3)\n",
        "    plt.figure(figsize=(11,11))\n",
        "    plt.imshow(np.transpose(grid,(1,2,0)))\n",
        "    plt.show()\n",
        "    print(\"labels:\",labels)"
      ],
      "metadata": {
        "id": "G-acBXoNCdjm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader,test_loader,val_loader = transformDS1(32,224)"
      ],
      "metadata": {
        "id": "4zDviO4RDKj3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "show_transformed_images(train_loader)"
      ],
      "metadata": {
        "id": "m4DpRYFZD7bW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.cuda\n",
        "\n",
        "\n",
        "def set_device():\n",
        "    if torch.cuda.is_available():\n",
        "        device = \"cuda:0\"\n",
        "    else:\n",
        "        device = \"cpu\"\n",
        "    return device"
      ],
      "metadata": {
        "id": "m8aP2EOzCFwB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_model(model,test_loader):\n",
        "    model.eval()\n",
        "    predicted_correct =0\n",
        "    total = 0\n",
        "    device = set_device()\n",
        "    with torch.no_grad():\n",
        "        for data in test_loader:\n",
        "            images,labels = data\n",
        "            images = images.to(device)\n",
        "            labels = labels.to(device)\n",
        "            total+=labels.size(0)\n",
        "            outputs = model(images)\n",
        "            _,predicted = torch.max(outputs,1)\n",
        "            predicted_correct += (predicted == labels).sum().item()\n",
        "    epoch_accuracy = 100.0* predicted_correct/total\n",
        "    print(\"Testing Data: Epoch Accuracy: %.3f\"%(epoch_accuracy))\n",
        "    return epoch_accuracy"
      ],
      "metadata": {
        "id": "j-dkyMCvB11N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "resnet_34 = models.resnet34(pretrained=False)\n",
        "num_classes = 35\n",
        "device = set_device()\n",
        "num_filters = resnet_34.fc.in_features\n",
        "resnet_34.fc = nn.Linear(num_filters, num_classes)\n",
        "resnet_34 = resnet_34.to(device)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(resnet_34.parameters(), lr=0.0002,momentum=0.9)\n",
        "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=100, eta_min=0.0001)\n",
        "epochCount=0\n",
        "n_epochs = 100"
      ],
      "metadata": {
        "id": "0ComUCBQu6dw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "Accuracies = [] \n",
        "valAccuracies = []\n",
        "total_steps = len(train_loader)\n",
        "t1 = time.time()\n",
        "device = set_device()\n",
        "print(\"-----Device:\"+device+\"-----\")\n",
        "for epoch in range(n_epochs):\n",
        "    print(\"Epoch number %d\" %(epoch+1))\n",
        "    resnet_34.train()\n",
        "    running_loss = 0.0\n",
        "    running_correct = 0.0\n",
        "    total = 0\n",
        "    for i, data in enumerate(train_loader):\n",
        "        images,labels = data\n",
        "        device = set_device()\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "        total+=labels.size(0)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = resnet_34(images)\n",
        "        _,predicted = torch.max(outputs.data,1)\n",
        "        loss = criterion(outputs,labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        \n",
        "        running_loss+=loss.item()\n",
        "        running_correct += (labels==predicted).sum().item()\n",
        "        if (i + 1) % 100 == 0:\n",
        "          validation_accuracy = 0\n",
        "          resnet_34.eval()\n",
        "          with torch.no_grad(): \n",
        "              val_correct = 0\n",
        "              val_total = 0\n",
        "              for data in val_loader:\n",
        "                  images, val_labels = data[0].to(device), data[1].to(device)\n",
        "                  outputs = resnet_34(images)\n",
        "                  \n",
        "                  # Validation set accuracy\n",
        "                  \n",
        "                  _,predicted = torch.max(outputs.data, 1)\n",
        "                  val_correct += (predicted == val_labels).sum().item()\n",
        "                  val_total  += val_labels.size(0)\n",
        "\n",
        "          validation_accuracy = (val_correct / val_total) * 100\n",
        "          training_accuracy = (running_correct / total) * 100\n",
        "          print('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}, Training Accuracy: {:.2f}%, Validation Accuracy: {:.2f}%'\n",
        "              .format(epoch + 1, n_epochs, i + 1, total_steps, loss.item(), training_accuracy , validation_accuracy))\n",
        "      \n",
        "    scheduler.step()\n",
        "    epoch_loss = running_loss/len(train_loader)\n",
        "    epoch_accuracy = 100.00 * running_correct/total\n",
        "    Accuracies.append(epoch_accuracy)\n",
        "    valAccuracies.append(validation_accuracy)\n",
        "    print(\"Training Data: Epoch Loss: %.3f, Epoch Accuracy: %.3f\"%(epoch_loss,epoch_accuracy))\n",
        "\n",
        "print(\"---Training finished in {} seconds---\".format(time.time()-t1))\n",
        "epochCount+=n_epochs\n",
        "torch.save(resnet_34.state_dict(), \"/content/35-Class-\"+str(epochCount)+\"-epoch.pt\")\n",
        "test_acc = evaluate_model(resnet_34,test_loader)\n",
        "dict = {'Training': Accuracies, 'Validation': valAccuracies} \n",
        "df = pd.DataFrame(dict)\n",
        "df.to_csv(\"/content/Accuracies\"+str(epochCount)+\".csv\")\n",
        "from google.colab import files\n",
        "files.download(\"/content/35-Class-\"+str(epochCount)+\"-epoch.pt\")\n",
        "files.download(\"/content/Accuracies\"+str(epochCount)+\".csv\")"
      ],
      "metadata": {
        "id": "cILaqvovCOBc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "resnet_34.load_state_dict(torch.load('35-Class-100-epoch.pt'))\n",
        "resnet_34.eval()"
      ],
      "metadata": {
        "id": "IqbDEVODziGG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(\"/content/Accuracies.csv\")\n",
        "Accuracies = df[\"Training\"]\n",
        "ValidationAccuracy = df[\"Validation\"]"
      ],
      "metadata": {
        "id": "Kgu4nYQf4DX8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plotting Accuracies Vs Epochs\n",
        "plt.plot(range(n_epochs),Accuracies)\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"Training Accuracies\")\n",
        "plt.title(\"Training Accuracy Vs Epochs\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "1CIk_kCGswrS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plotting Validation Accuracies Vs Train Accuracies on Epochs\n",
        "plt.plot(range(n_epochs),Accuracies, label=\"Training\")\n",
        "plt.plot(range(n_epochs),ValidationAccuracy, label=\"Validation\")\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"Accuracies\")\n",
        "plt.title(\"Training vs Validation Accuracies\")\n",
        "plt.legend()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "BDClQED6s0W-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision.models.resnet import resnet34\n",
        "#Calculate Confusion Matrix\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import seaborn as sn\n",
        "import pandas as pd\n",
        "from sklearn.metrics import confusion_matrix,accuracy_score,precision_score,recall_score,ConfusionMatrixDisplay\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import seaborn as sn\n",
        "import pandas as pd\n",
        "\n",
        "y_pred = []\n",
        "y_true = []\n",
        "\n",
        "# iterate over test data\n",
        "for data in test_loader:\n",
        "        inputs, labels = data[0].to(device), data[1].to(device)\n",
        "        output = resnet_34(inputs) # Feed Network\n",
        "\n",
        "        output = (torch.max(torch.exp(output), 1)[1]).data.cpu().numpy()\n",
        "        y_pred.extend(output) # Save Prediction\n",
        "        \n",
        "        labels = labels.data.cpu().numpy()\n",
        "        y_true.extend(labels) # Save Truth\n",
        "\n",
        "# constant for classes\n",
        "classes = ('0', '1', ' 2', ' 3', '4','5','6','7','8','9','10','11','12','13','14','15','16','17','18','19','20','21','22','23','24','25','26','27','28','29','30','31','32','33','34')\n",
        "\n",
        "# Build confusion matrix\n",
        "confusion_matrix(y_true, y_pred)\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix(y_true, y_pred),\n",
        "                              display_labels=classes)\n",
        "fig, ax = plt.subplots(figsize=(13,13))\n",
        "plt.title(\"Confusion Matrix ResNet 34 (35-Classes)\")\n",
        "disp.plot(ax=ax)\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "KZ4sH_Xk1Z2W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Precision Calculation and Recall calculation\n",
        "from sklearn.metrics import precision_score, recall_score,f1_score\n",
        "\n",
        "print(\"Precision Macro:{:.2f}\".format(precision_score(y_true, y_pred, average='macro')))\n",
        "print(\"Precision Micro:{:.2f}\".format(precision_score(y_true,y_pred,average='micro')))\n",
        "print(\"Recall Macro:{:.2f}\".format(recall_score(y_true,y_pred,average='macro')))\n",
        "print(\"Recall Micro:{:.2f}\".format(recall_score(y_true,y_pred,average='micro')))\n",
        "print(\"F1-Score Micro:{:.2f}\".format(f1_score(y_true,y_pred,average='micro')))\n",
        "print(\"F1-Score Micro:{:.2f}\".format(f1_score(y_true,y_pred,average='micro')))"
      ],
      "metadata": {
        "id": "7zBjcBbxwnRG"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}