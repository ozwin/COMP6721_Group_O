{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1f5d6e24",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "from google.colab import files\n",
    "import os\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import torchvision.models as models\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import torchvision\n",
    "from torchsummary import summary\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "from PIL import Image as PilImage\n",
    "from torchvision import models, transforms\n",
    "import torch\n",
    "import json\n",
    "import plotly.io as pio\n",
    "pio.renderers.default = \"png\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "db5b52da",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ozwin\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\ozwin\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1         [-1, 64, 162, 162]           9,408\n",
      "       BatchNorm2d-2         [-1, 64, 162, 162]             128\n",
      "              ReLU-3         [-1, 64, 162, 162]               0\n",
      "         MaxPool2d-4           [-1, 64, 81, 81]               0\n",
      "            Conv2d-5           [-1, 64, 81, 81]          36,864\n",
      "       BatchNorm2d-6           [-1, 64, 81, 81]             128\n",
      "              ReLU-7           [-1, 64, 81, 81]               0\n",
      "            Conv2d-8           [-1, 64, 81, 81]          36,864\n",
      "       BatchNorm2d-9           [-1, 64, 81, 81]             128\n",
      "             ReLU-10           [-1, 64, 81, 81]               0\n",
      "       BasicBlock-11           [-1, 64, 81, 81]               0\n",
      "           Conv2d-12           [-1, 64, 81, 81]          36,864\n",
      "      BatchNorm2d-13           [-1, 64, 81, 81]             128\n",
      "             ReLU-14           [-1, 64, 81, 81]               0\n",
      "           Conv2d-15           [-1, 64, 81, 81]          36,864\n",
      "      BatchNorm2d-16           [-1, 64, 81, 81]             128\n",
      "             ReLU-17           [-1, 64, 81, 81]               0\n",
      "       BasicBlock-18           [-1, 64, 81, 81]               0\n",
      "           Conv2d-19          [-1, 128, 41, 41]          73,728\n",
      "      BatchNorm2d-20          [-1, 128, 41, 41]             256\n",
      "             ReLU-21          [-1, 128, 41, 41]               0\n",
      "           Conv2d-22          [-1, 128, 41, 41]         147,456\n",
      "      BatchNorm2d-23          [-1, 128, 41, 41]             256\n",
      "           Conv2d-24          [-1, 128, 41, 41]           8,192\n",
      "      BatchNorm2d-25          [-1, 128, 41, 41]             256\n",
      "             ReLU-26          [-1, 128, 41, 41]               0\n",
      "       BasicBlock-27          [-1, 128, 41, 41]               0\n",
      "           Conv2d-28          [-1, 128, 41, 41]         147,456\n",
      "      BatchNorm2d-29          [-1, 128, 41, 41]             256\n",
      "             ReLU-30          [-1, 128, 41, 41]               0\n",
      "           Conv2d-31          [-1, 128, 41, 41]         147,456\n",
      "      BatchNorm2d-32          [-1, 128, 41, 41]             256\n",
      "             ReLU-33          [-1, 128, 41, 41]               0\n",
      "       BasicBlock-34          [-1, 128, 41, 41]               0\n",
      "           Conv2d-35          [-1, 256, 21, 21]         294,912\n",
      "      BatchNorm2d-36          [-1, 256, 21, 21]             512\n",
      "             ReLU-37          [-1, 256, 21, 21]               0\n",
      "           Conv2d-38          [-1, 256, 21, 21]         589,824\n",
      "      BatchNorm2d-39          [-1, 256, 21, 21]             512\n",
      "           Conv2d-40          [-1, 256, 21, 21]          32,768\n",
      "      BatchNorm2d-41          [-1, 256, 21, 21]             512\n",
      "             ReLU-42          [-1, 256, 21, 21]               0\n",
      "       BasicBlock-43          [-1, 256, 21, 21]               0\n",
      "           Conv2d-44          [-1, 256, 21, 21]         589,824\n",
      "      BatchNorm2d-45          [-1, 256, 21, 21]             512\n",
      "             ReLU-46          [-1, 256, 21, 21]               0\n",
      "           Conv2d-47          [-1, 256, 21, 21]         589,824\n",
      "      BatchNorm2d-48          [-1, 256, 21, 21]             512\n",
      "             ReLU-49          [-1, 256, 21, 21]               0\n",
      "       BasicBlock-50          [-1, 256, 21, 21]               0\n",
      "           Conv2d-51          [-1, 512, 11, 11]       1,179,648\n",
      "      BatchNorm2d-52          [-1, 512, 11, 11]           1,024\n",
      "             ReLU-53          [-1, 512, 11, 11]               0\n",
      "           Conv2d-54          [-1, 512, 11, 11]       2,359,296\n",
      "      BatchNorm2d-55          [-1, 512, 11, 11]           1,024\n",
      "           Conv2d-56          [-1, 512, 11, 11]         131,072\n",
      "      BatchNorm2d-57          [-1, 512, 11, 11]           1,024\n",
      "             ReLU-58          [-1, 512, 11, 11]               0\n",
      "       BasicBlock-59          [-1, 512, 11, 11]               0\n",
      "           Conv2d-60          [-1, 512, 11, 11]       2,359,296\n",
      "      BatchNorm2d-61          [-1, 512, 11, 11]           1,024\n",
      "             ReLU-62          [-1, 512, 11, 11]               0\n",
      "           Conv2d-63          [-1, 512, 11, 11]       2,359,296\n",
      "      BatchNorm2d-64          [-1, 512, 11, 11]           1,024\n",
      "             ReLU-65          [-1, 512, 11, 11]               0\n",
      "       BasicBlock-66          [-1, 512, 11, 11]               0\n",
      "AdaptiveAvgPool2d-67            [-1, 512, 1, 1]               0\n",
      "           Linear-68                    [-1, 5]           2,565\n",
      "================================================================\n",
      "Total params: 11,179,077\n",
      "Trainable params: 11,179,077\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 1.20\n",
      "Forward/backward pass size (MB): 134.11\n",
      "Params size (MB): 42.64\n",
      "Estimated Total Size (MB): 177.96\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "num_classes=5 #based on dataset change the values 5,15,35\n",
    "# Change the model to use model of your choice from resnet18,resne34,mobileNetv2\n",
    "model = models.resnet18(pretrained=False, num_classes=num_classes)\n",
    "# navigate to Output/{Model_Selected}/Weights folder choose the  model weight file based on the dataset you want to test against\n",
    "model.load_state_dict(torch.load('/content/5-class-100-epochos-output.pt'))  # This is using model trained for 100 epochos on dataset 1 with 5 classes\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\") #this will use GPU if avilable\n",
    "model.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ae18d5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_fath = \"/content/5-class/preprocessed-cleaned-set/test/class-4/0d32920975d1d318089d4b17920669e4.jpg\" #specify the image path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61d188fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model):\n",
    "    def transform_image():\n",
    "        # for dataset 1 use mean=[0.3461, 0.3217, 0.2852], std=[0.2870, 0.2718, 0.2510]\n",
    "        # for dataset 2 use mean=[] std=[] need to calculate this based on the dataset\n",
    "        # for dataset 3 use mean=[] std=[] need to calculate this based on the dataset\n",
    "        transform = transforms.Compose([transforms.Resize(255),\n",
    "                                            transforms.CenterCrop(224),\n",
    "                                            transforms.ToTensor(),\n",
    "                                            transforms.Normalize(mean=[0.3461, 0.3217, 0.2852], std=[0.2870, 0.2718, 0.2510] \n",
    "                                                )])\n",
    "        image = PilImage.open(img_fath)\n",
    "        return transform(image).unsqueeze(0) #for single image\n",
    "\n",
    "    model.eval()\n",
    "    \n",
    "    labels=[]  #specify the labels of the dataset selected\n",
    "    for i in range(num_classes):\n",
    "        labels+=f'class-{i}'\n",
    "\n",
    "    def get_prediction():\n",
    "        tensor = transform_image()\n",
    "        tensor=tensor.to(device)\n",
    "        output = model(tensor)\n",
    "        probs = torch.nn.functional.softmax(output, dim=1)\n",
    "        print(probs.cpu().detach().numpy())\n",
    "        conf, classes = torch.max(probs, 1)\n",
    "        return conf.item(), labels[classes.item()],classes.item()\n",
    "\n",
    "    image_path = img_fath\n",
    "    image = plt.imread(image_path)\n",
    "    plt.imshow(image)\n",
    "\n",
    "    with open(image_path, 'rb') as f:\n",
    "    \n",
    "        conf,y_pre,index=get_prediction()\n",
    "        print(y_pre, ' at confidence score:{0:.2f}'.format(conf))\n",
    "        return (y_pre, ' at confidence score:{0:.2f}'.format(conf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c2fff33",
   "metadata": {},
   "outputs": [],
   "source": [
    "output, index = predict(model) \n",
    "print(output)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.8 64-bit (microsoft store)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "7b09aa25085201113d172ec21b2171879613482346442a3be94d8c1c570d2f9e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
